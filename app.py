import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from deltalake import DeltaTable
from datetime import datetime, timedelta
import pytz
import os

# í˜ì´ì§€ ê¸°ë³¸ ì„¸íŒ…
st.set_page_config(
    layout="wide",
    page_title="GDELT AI Analytics Platform",
    page_icon="ğŸŒ",
    initial_sidebar_state="expanded"
)

# MinIO ì ‘ì† ì •ë³´ 
MINIO_ENDPOINT = os.getenv("MINIO_ENDPOINT", "http://localhost:9000")
MINIO_ACCESS_KEY = os.getenv("MINIO_ACCESS_KEY", "minioadmin")
MINIO_SECRET_KEY = os.getenv("MINIO_SECRET_KEY", "minioadmin")

storage_options = {
    "AWS_ACCESS_KEY_ID": MINIO_ACCESS_KEY,
    "AWS_SECRET_ACCESS_KEY": MINIO_SECRET_KEY,
    "AWS_ENDPOINT_URL": MINIO_ENDPOINT,
    "AWS_S3_ALLOW_UNSAFE_RENAME": "true",
    "AWS_REGION": "us-east-1",
    "AWS_ALLOW_HTTP": "true"
}

# MinIOì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
@st.cache_data(ttl=60)
def load_ai_summaries():
    """Gold Layer - AI ìš”ì•½ ë°ì´í„°"""
    try:
        dt = DeltaTable("s3://warehouse/gold/gdelt_ai_summaries", storage_options=storage_options)
        df = dt.to_pandas()
        if 'event_date' in df.columns:
            df['event_date'] = pd.to_datetime(df['event_date'])
        return df
    except Exception as e:
        st.error(f"AI Summaries ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return None

@st.cache_data(ttl=60)
def load_llm_context():
    """Gold Layer - LLM ì»¨í…ìŠ¤íŠ¸ ë°ì´í„°"""
    try:
        dt = DeltaTable("s3://warehouse/gold/gold_llm_context", storage_options=storage_options)
        df = dt.to_pandas()
        if 'event_date' in df.columns:
            df['event_date'] = pd.to_datetime(df['event_date'])
        return df
    except Exception as e:
        st.warning(f"LLM Context ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return None

@st.cache_data(ttl=120)
def load_silver_events():
    """Silver Layer - ì •ì œëœ ì´ë²¤íŠ¸ ë°ì´í„°"""
    try:
        dt = DeltaTable("s3://warehouse/silver/gdelt_events", storage_options=storage_options)
        df = dt.to_pandas()
        if 'event_date' in df.columns:
            df['event_date'] = pd.to_datetime(df['event_date'])
        return df
    except Exception as e:
        st.warning(f"Silver Events ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return None

def check_connection():
    """MinIO ì—°ê²° ìƒíƒœ ì²´í¬"""
    try:
        load_ai_summaries()
        return True
    except:
        return False

# [ì‚¬ì´ë“œë°”] ë„¤ë¹„ê²Œì´ì…˜ & í•„í„°
st.sidebar.title("ğŸŒ GDELT Analytics")
st.sidebar.markdown("---")

page = st.sidebar.radio(
    "í˜ì´ì§€ ì„ íƒ",
    ["ëŒ€ì‹œë³´ë“œ", "AI ì¸ì‚¬ì´íŠ¸", "ë°ì´í„° íƒìƒ‰", "íŒŒì´í”„ë¼ì¸ ëª¨ë‹ˆí„°"]
)

st.sidebar.markdown("---")
st.sidebar.caption(f"**Backend:** Kubernetes (Kind)")
st.sidebar.caption(f"**Storage:** MinIO + Delta Lake")
st.sidebar.caption(f"**Engine:** Spark 3.4.3 + dbt")
st.sidebar.caption(f"**AI Model:** Gemini 2.5 Flash")

# [í˜ì´ì§€ 1] ëŒ€ì‹œë³´ë“œ
if page == "ëŒ€ì‹œë³´ë“œ":
    st.title("ğŸŒ GDELT AI Analytics Platform")
    st.markdown("### ì‹¤ì‹œê°„ êµ­ì œ ë‰´ìŠ¤ ì´ë²¤íŠ¸ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

    # ë°ì´í„° ë¡œë“œ
    df_ai = load_ai_summaries()
    df_context = load_llm_context()
    df_silver = load_silver_events()

    if df_ai is None:
        st.error("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. MinIO ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()

    # ìƒë‹¨ ë©”íŠ¸ë¦­
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        total_events = len(df_ai) if df_ai is not None else 0
        st.metric("ì²˜ë¦¬ëœ ì´ë²¤íŠ¸", f"{total_events:,}ê±´")

    with col2:
        if df_context is not None and 'num_mentions' in df_context.columns:
            total_mentions = int(df_context['num_mentions'].sum())
            st.metric("ì´ ì–¸ê¸‰ ìˆ˜", f"{total_mentions:,}")
        else:
            st.metric("ì´ ì–¸ê¸‰ ìˆ˜", "N/A")

    with col3:
        if df_ai is not None and 'event_date' in df_ai.columns:
            latest_date = df_ai['event_date'].max()
            st.metric("ìµœì‹  ë°ì´í„°", latest_date.strftime('%Y-%m-%d') if pd.notna(latest_date) else "N/A")
        else:
            st.metric("ìµœì‹  ë°ì´í„°", "N/A")

    with col4:
        st.metric("AI ëª¨ë¸", "Gemini 2.5")

    st.divider()

    # ì‹œê°í™” ì„¹ì…˜
    if df_context is not None and not df_context.empty:
        col_left, col_right = st.columns(2)

        with col_left:
            st.subheader("ì‹œê°„ë³„ ì´ë²¤íŠ¸ íŠ¸ë Œë“œ")
            if 'event_date' in df_context.columns:
                daily_counts = df_context.groupby('event_date').size().reset_index(name='count')
                daily_counts = daily_counts.sort_values('event_date')

                fig = px.line(
                    daily_counts,
                    x='event_date',
                    y='count',
                    labels={'event_date': 'ë‚ ì§œ', 'count': 'ì´ë²¤íŠ¸ ìˆ˜'},
                    template='plotly_white'
                )
                fig.update_traces(line_color='#1f77b4', line_width=2)
                st.plotly_chart(fig, use_container_width=True)

        with col_right:
            st.subheader("í‰ê·  ê°ì • ì ìˆ˜ ì¶”ì´")
            if 'avg_tone' in df_context.columns and 'event_date' in df_context.columns:
                tone_by_date = df_context.groupby('event_date')['avg_tone'].mean().reset_index()
                tone_by_date = tone_by_date.sort_values('event_date')

                fig = px.area(
                    tone_by_date,
                    x='event_date',
                    y='avg_tone',
                    labels={'event_date': 'ë‚ ì§œ', 'avg_tone': 'í‰ê·  ê°ì • ì ìˆ˜'},
                    template='plotly_white'
                )
                fig.add_hline(y=0, line_dash="dash", line_color="gray", annotation_text="ì¤‘ë¦½")
                fig.update_traces(fillcolor='rgba(31, 119, 180, 0.3)')
                st.plotly_chart(fig, use_container_width=True)

    # ìµœì‹  AI ìš”ì•½ ë¯¸ë¦¬ë³´ê¸°
    st.subheader("ìµœê·¼ AI ìš”ì•½ Top 5")
    if df_ai is not None and not df_ai.empty:
        recent = df_ai.sort_values('event_date', ascending=False).head(5)

        for idx, row in recent.iterrows():
            with st.expander(f"{row.get('event_date', 'N/A')} - Event ID: {row.get('global_event_id', 'N/A')}"):
                st.success(f"**AI ìš”ì•½:** {row.get('ai_summary', 'ìš”ì•½ ì—†ìŒ')}")

                if 'num_mentions' in row:
                    st.caption(f"ì–¸ê¸‰ íšŸìˆ˜: {row['num_mentions']}")
                if 'avg_tone' in row:
                    tone_emoji = "ğŸ˜Š" if row['avg_tone'] > 0 else "ğŸ˜" if row['avg_tone'] < 0 else "ğŸ˜"
                    st.caption(f"{tone_emoji} ê°ì • ì ìˆ˜: {row['avg_tone']:.2f}")

# [í˜ì´ì§€ 2] AI ì¸ì‚¬ì´íŠ¸
elif page == "AI ì¸ì‚¬ì´íŠ¸":
    st.title("GDELT AI Insight Inspector")
    st.markdown("### Raw Data vs AI Summary ë¹„êµ ë¶„ì„")

    df = load_ai_summaries()

    if df is None or df.empty:
        st.error("AI ìš”ì•½ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
        st.stop()

    # ìµœì‹ ìˆœ ì •ë ¬
    if 'event_date' in df.columns:
        df = df.sort_values(by='event_date', ascending=False)

    # ìƒë‹¨: ìš”ì•½ ì§€í‘œ
    col1, col2, col3 = st.columns(3)
    col1.metric("ë¶„ì„ëœ ì´ë²¤íŠ¸", f"{len(df):,}ê±´")
    col2.metric("AI ëª¨ë¸", "Gemini 2.5 Flash")

    if 'num_mentions' in df.columns:
        avg_mentions = df['num_mentions'].mean()
        col3.metric("í‰ê·  ì–¸ê¸‰ ìˆ˜", f"{avg_mentions:.1f}")

    st.divider()

    # í•„í„° ì˜µì…˜
    col_filter1, col_filter2 = st.columns([2, 1])

    with col_filter1:
        # ë‚ ì§œ í•„í„°
        if 'event_date' in df.columns:
            date_options = sorted(df['event_date'].dt.date.unique(), reverse=True)
            selected_date = st.selectbox(
                "ë‚ ì§œ ì„ íƒ",
                ["ì „ì²´"] + [str(d) for d in date_options]
            )

            if selected_date != "ì „ì²´":
                df = df[df['event_date'].dt.date == pd.to_datetime(selected_date).date()]

    with col_filter2:
        # ì •ë ¬ ê¸°ì¤€
        sort_by = st.selectbox(
            "ì •ë ¬ ê¸°ì¤€",
            ["ìµœì‹ ìˆœ", "ì–¸ê¸‰ ë§ì€ìˆœ"] if 'num_mentions' in df.columns else ["ìµœì‹ ìˆœ"]
        )

        if sort_by == "ì–¸ê¸‰ ë§ì€ìˆœ" and 'num_mentions' in df.columns:
            df = df.sort_values('num_mentions', ascending=False)

    st.divider()

    # ë©”ì¸: Before & After ë¹„êµ
    st.subheader("ì´ë²¤íŠ¸ ìƒì„¸ ë¶„ì„")

    # ì´ë²¤íŠ¸ ë¦¬ìŠ¤íŠ¸
    if df.empty:
        st.warning("ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        event_options = df.apply(
            lambda row: f"{row.get('event_date', 'N/A')} | ID: {row['global_event_id']} | {row.get('ai_summary', '')[:50]}...",
            axis=1
        ).tolist()

        selected_idx = st.selectbox(
            "ë¶„ì„í•  ì´ë²¤íŠ¸ ì„ íƒ:",
            range(len(event_options)),
            format_func=lambda i: event_options[i]
        )

        if selected_idx is not None:
            row = df.iloc[selected_idx]

            # ë©”íƒ€ ì •ë³´
            meta_col1, meta_col2, meta_col3 = st.columns(3)
            with meta_col1:
                st.info(f"**Event ID:** {row.get('global_event_id', 'N/A')}")
            with meta_col2:
                st.info(f"**ë‚ ì§œ:** {row.get('event_date', 'N/A')}")
            with meta_col3:
                if 'num_mentions' in row:
                    st.info(f"**ì–¸ê¸‰ ìˆ˜:** {row['num_mentions']}")

            st.divider()

            # Before & After ë¹„êµ
            c1, c2 = st.columns(2)

            with c1:
                st.markdown("#### AI Summary (Output)")
                st.success(f"{row.get('ai_summary', 'ìš”ì•½ ì—†ìŒ')}")
                st.caption("Gemini 2.5 Flashê°€ ìƒì„±í•œ í•œêµ­ì–´ ìš”ì•½")

            with c2:
                st.markdown("#### Raw Context (Input)")
                context_text = row.get('llm_content_text', 'No Context')
                st.text_area(
                    label="ì›ë³¸ ë°ì´í„°",
                    value=context_text,
                    height=300,
                    disabled=True,
                    label_visibility="collapsed"
                )
                st.caption("Spark + dbtê°€ ì¡°ë¦½í•œ ì›ë³¸ ì»¨í…ìŠ¤íŠ¸")

# [í˜ì´ì§€ 3] ë°ì´í„° íƒìƒ‰
elif page == "ë°ì´í„° íƒìƒ‰":
    st.title("GDELT ë°ì´í„° íƒìƒ‰")
    st.markdown("### Silver & Gold Layer ì›ë³¸ ë°ì´í„° ì¡°íšŒ")

    # ë ˆì´ì–´ ì„ íƒ
    layer = st.radio(
        "ë°ì´í„° ë ˆì´ì–´ ì„ íƒ:",
        ["Gold - LLM Context", "Gold - AI Summaries", "Silver - Events"],
        horizontal=True
    )

    # ë°ì´í„° ë¡œë“œ
    if layer == "Gold - LLM Context":
        df = load_llm_context()
        table_path = "s3://warehouse/gold/gold_llm_context"
    elif layer == "Gold - AI Summaries":
        df = load_ai_summaries()
        table_path = "s3://warehouse/gold/gdelt_ai_summaries"
    else:
        df = load_silver_events()
        table_path = "s3://warehouse/silver/events"

    if df is None or df.empty:
        st.warning(f"{layer} ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    # ë°ì´í„° ì •ë³´
    col1, col2, col3 = st.columns(3)
    col1.metric("ì´ ë ˆì½”ë“œ ìˆ˜", f"{len(df):,}")
    col2.metric("ì»¬ëŸ¼ ìˆ˜", f"{len(df.columns)}")

    if 'event_date' in df.columns:
        date_range = f"{df['event_date'].min().date()} ~ {df['event_date'].max().date()}"
        col3.metric("ë°ì´í„° ê¸°ê°„", date_range)

    st.divider()

    # ì»¬ëŸ¼ ì •ë³´
    with st.expander("í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ë³´ê¸°"):
        schema_df = pd.DataFrame({
            'ì»¬ëŸ¼ëª…': df.columns,
            'ë°ì´í„° íƒ€ì…': [str(dtype) for dtype in df.dtypes],
            'Null ê°œìˆ˜': [df[col].isna().sum() for col in df.columns],
            'Null ë¹„ìœ¨ (%)': [f"{(df[col].isna().sum() / len(df) * 100):.1f}" for col in df.columns]
        })
        st.dataframe(schema_df, use_container_width=True)

    st.caption(f"**í…Œì´ë¸” ê²½ë¡œ:** `{table_path}`")

    # í•„í„° & ê²€ìƒ‰
    st.subheader("ë°ì´í„° í•„í„°ë§")

    col_search1, col_search2 = st.columns(2)

    with col_search1:
        # ë‚ ì§œ í•„í„°
        if 'event_date' in df.columns:
            min_date = df['event_date'].min().date()
            max_date = df['event_date'].max().date()

            date_range = st.date_input(
                "ë‚ ì§œ ë²”ìœ„:",
                value=(min_date, max_date),
                min_value=min_date,
                max_value=max_date
            )

            if len(date_range) == 2:
                df = df[
                    (df['event_date'].dt.date >= date_range[0]) &
                    (df['event_date'].dt.date <= date_range[1])
                ]

    with col_search2:
        # í…ìŠ¤íŠ¸ ê²€ìƒ‰
        search_query = st.text_input("í…ìŠ¤íŠ¸ ê²€ìƒ‰ (ëª¨ë“  ì»¬ëŸ¼):")
        if search_query:
            mask = df.astype(str).apply(lambda row: row.str.contains(search_query, case=False, na=False).any(), axis=1)
            df = df[mask]

    # í‘œì‹œí•  í–‰ ìˆ˜
    show_rows = st.slider("í‘œì‹œí•  í–‰ ìˆ˜:", 10, 1000, 100, step=10)

    st.divider()

    # ë°ì´í„° í…Œì´ë¸”
    st.subheader(f"ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ì´ {len(df):,}ê±´)")
    st.dataframe(df.head(show_rows), use_container_width=True)

    # CSV ë‹¤ìš´ë¡œë“œ
    csv = df.head(show_rows).to_csv(index=False).encode('utf-8-sig')
    st.download_button(
        label="CSV ë‹¤ìš´ë¡œë“œ",
        data=csv,
        file_name=f"gdelt_{layer.replace(' ', '_').lower()}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
        mime="text/csv"
    )

# [í˜ì´ì§€ 4] íŒŒì´í”„ë¼ì¸ ëª¨ë‹ˆí„°
elif page == "íŒŒì´í”„ë¼ì¸ ëª¨ë‹ˆí„°":
    st.title("GDELT íŒŒì´í”„ë¼ì¸ ëª¨ë‹ˆí„°")
    st.markdown("### Delta Lake ë©”íƒ€ë°ì´í„° & ë°ì´í„° í’ˆì§ˆ ì²´í¬")

    # ë ˆì´ì–´ë³„ ìƒíƒœ ì²´í¬
    st.subheader("ë ˆì´ì–´ë³„ ë°ì´í„° í˜„í™©")

    layers_info = []

    # Silver Layer
    df_silver = load_silver_events()
    if df_silver is not None:
        silver_info = {
            "ë ˆì´ì–´": "Silver Events",
            "ê²½ë¡œ": "s3://warehouse/silver/events",
            "ë ˆì½”ë“œ ìˆ˜": f"{len(df_silver):,}",
            "ìµœì‹  ë°ì´í„°": df_silver['event_date'].max().strftime('%Y-%m-%d %H:%M') if 'event_date' in df_silver.columns else "N/A",
            "ìƒíƒœ": "ì •ìƒ"
        }
        layers_info.append(silver_info)
    else:
        layers_info.append({
            "ë ˆì´ì–´": "Silver Events",
            "ê²½ë¡œ": "s3://warehouse/silver/events",
            "ë ˆì½”ë“œ ìˆ˜": "N/A",
            "ìµœì‹  ë°ì´í„°": "N/A",
            "ìƒíƒœ": "ì˜¤ë¥˜"
        })

    # Gold LLM Context
    df_context = load_llm_context()
    if df_context is not None:
        context_info = {
            "ë ˆì´ì–´": "Gold LLM Context",
            "ê²½ë¡œ": "s3://warehouse/gold/gold_llm_context",
            "ë ˆì½”ë“œ ìˆ˜": f"{len(df_context):,}",
            "ìµœì‹  ë°ì´í„°": df_context['event_date'].max().strftime('%Y-%m-%d %H:%M') if 'event_date' in df_context.columns else "N/A",
            "ìƒíƒœ": "ì •ìƒ"
        }
        layers_info.append(context_info)
    else:
        layers_info.append({
            "ë ˆì´ì–´": "Gold LLM Context",
            "ê²½ë¡œ": "s3://warehouse/gold/gold_llm_context",
            "ë ˆì½”ë“œ ìˆ˜": "N/A",
            "ìµœì‹  ë°ì´í„°": "N/A",
            "ìƒíƒœ": "ì˜¤ë¥˜"
        })

    # Gold AI Summaries
    df_ai = load_ai_summaries()
    if df_ai is not None:
        ai_info = {
            "ë ˆì´ì–´": "Gold AI Summaries",
            "ê²½ë¡œ": "s3://warehouse/gold/gdelt_ai_summaries",
            "ë ˆì½”ë“œ ìˆ˜": f"{len(df_ai):,}",
            "ìµœì‹  ë°ì´í„°": df_ai['event_date'].max().strftime('%Y-%m-%d %H:%M') if 'event_date' in df_ai.columns else "N/A",
            "ìƒíƒœ": "ì •ìƒ"
        }
        layers_info.append(ai_info)
    else:
        layers_info.append({
            "ë ˆì´ì–´": "Gold AI Summaries",
            "ê²½ë¡œ": "s3://warehouse/gold/gdelt_ai_summaries",
            "ë ˆì½”ë“œ ìˆ˜": "N/A",
            "ìµœì‹  ë°ì´í„°": "N/A",
            "ìƒíƒœ": "ì˜¤ë¥˜"
        })

    # í…Œì´ë¸”ë¡œ í‘œì‹œ
    layers_df = pd.DataFrame(layers_info)
    st.dataframe(layers_df, use_container_width=True, hide_index=True)

    st.divider()

    # ë°ì´í„° í’ˆì§ˆ ì²´í¬
    st.subheader("ë°ì´í„° í’ˆì§ˆ ë¶„ì„")

    if df_ai is not None and not df_ai.empty:
        quality_col1, quality_col2 = st.columns(2)

        with quality_col1:
            st.markdown("#### AI ìš”ì•½ í’ˆì§ˆ")

            # AI ìš”ì•½ ê¸¸ì´ ë¶„ì„
            if 'ai_summary' in df_ai.columns:
                df_ai['summary_length'] = df_ai['ai_summary'].astype(str).str.len()
                avg_length = df_ai['summary_length'].mean()

                st.metric("í‰ê·  ìš”ì•½ ê¸¸ì´", f"{avg_length:.0f} ì")

                # ìš”ì•½ ì‹¤íŒ¨ ê±´ìˆ˜
                failed = (df_ai['ai_summary'].astype(str).str.contains('ìš”ì•½ ì‹¤íŒ¨|No Summary', na=True)).sum()
                success_rate = ((len(df_ai) - failed) / len(df_ai) * 100) if len(df_ai) > 0 else 0
                st.metric("ìš”ì•½ ì„±ê³µë¥ ", f"{success_rate:.1f}%")

        with quality_col2:
            st.markdown("#### ë°ì´í„° ì‹ ì„ ë„")

            if 'event_date' in df_ai.columns:
                latest = df_ai['event_date'].max()
                now = pd.Timestamp.now()
                age_hours = (now - latest).total_seconds() / 3600

                st.metric("ìµœì‹  ë°ì´í„° ì‹œì ", latest.strftime('%Y-%m-%d %H:%M'))

                if age_hours < 24:
                    st.success(f"ì‹ ì„ í•¨")
                elif age_hours < 48:
                    st.warning(f"ì£¼ì˜ (ì•½ {age_hours/24:.1f}ì¼ ì „)")
                else:
                    st.error(f"ì˜¤ë˜ë¨ (ì•½ {age_hours/24:.1f}ì¼ ì „)")

    st.divider()

    # ì‹œìŠ¤í…œ ì •ë³´
    st.subheader("ì‹œìŠ¤í…œ ì •ë³´")

    sys_col1, sys_col2 = st.columns(2)

    with sys_col1:
        st.info(f"""
        **MinIO Endpoint:** `{MINIO_ENDPOINT}`
        **Access Key:** `{MINIO_ACCESS_KEY[:5]}***`
        **Region:** `us-east-1`
        **Protocol:** `HTTP`
        """)

    with sys_col2:
        st.info(f"""
        **Kubernetes:** Kind (Local)
        **Spark Version:** 3.5
        **Delta Lake:** 2.4.0
        **dbt Core:** 1.8+
        """)

    # ì ‘ì† ê°€ì´ë“œ
    with st.expander("MinIO í¬íŠ¸ í¬ì›Œë”© ì„¤ì •"):
        st.code("""
# MinIO ì½˜ì†” (UI)
kubectl port-forward svc/minio-console 9001:9001 -n airflow

# MinIO API (S3)
kubectl port-forward svc/minio 9000:9000 -n airflow

# Airflow UI
kubectl port-forward svc/airflow-webserver 8080:8080 -n airflow
        """, language="bash")

# [Footer]
st.divider()
st.caption("GDELT Data Platform | Powered by Kubernetes + Spark + Delta Lake + Gemini AI")
